{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing with BERT\n",
    "\n",
    "Bert Model Download: https://github.com/google-research/bert#pre-trained-models\n",
    "\n",
    "inspired by: https://github.com/llSourcell/bert-as-service\n",
    "\n",
    "DOC: https://bert-as-service.readthedocs.io/en/latest/section/get-start.html#start-the-bert-service\n",
    "\n",
    "Install BERT:\n",
    "pip install bert-serving-server\n",
    "pip install bert-serving-client\n",
    "Python 3.5 and Tensorflow 1.10 required\n",
    "\n",
    "Download pretrained model:\n",
    "\n",
    "https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
    "\n",
    "add unziped to /tmp/uncased_L-12_H-768_A-12/\n",
    "\n",
    "then start the service by : bert-serving-start -model_dir /tmp/uncased_L-12_H-768_A-12/ -num_worker=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_serving.client import BertClient\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "from nltk import tokenize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train Dataset of size: 18678 \n",
      " Test Dataset of size: 9201\n",
      "Size of FakeNews: 12167 \n",
      " Size of Real News: 15712\n",
      "FakeNews Anteil: 0.43642167940026544\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4714</th>\n",
       "      <td>'D**k-Waving Berlusconi Knockoff': Late-Night ...</td>\n",
       "      <td>Share on Twitter \\nDuring the third and final ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2858</th>\n",
       "      <td>Ikea crea un carril rápido para solteros</td>\n",
       "      <td>Ikea crea un carril rápido para solteros LOS C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25695</th>\n",
       "      <td>Congo forces kill 26 protesters against leader...</td>\n",
       "      <td>Security forces shot dead at least 26 protest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>Get Ready For Civil Unrest</td>\n",
       "      <td>Get Ready For Civil Unrest 10/31/2016 \\nECONOM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028</th>\n",
       "      <td>Review: Brit Bennett’s “The Mothers”</td>\n",
       "      <td>Email \\nThe mothers referred to in the title o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "4714   'D**k-Waving Berlusconi Knockoff': Late-Night ...   \n",
       "2858            Ikea crea un carril rápido para solteros   \n",
       "25695  Congo forces kill 26 protesters against leader...   \n",
       "631                           Get Ready For Civil Unrest   \n",
       "2028                Review: Brit Bennett’s “The Mothers”   \n",
       "\n",
       "                                                 content  \n",
       "4714   Share on Twitter \\nDuring the third and final ...  \n",
       "2858   Ikea crea un carril rápido para solteros LOS C...  \n",
       "25695   Security forces shot dead at least 26 protest...  \n",
       "631    Get Ready For Civil Unrest 10/31/2016 \\nECONOM...  \n",
       "2028   Email \\nThe mothers referred to in the title o...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = pd.read_csv('../data/mixed_news/news_dataset.csv')\n",
    "news = news.dropna(subset=['title','content'])\n",
    "news = news[news.content != ' ']\n",
    "news = news[news.title != ' ']\n",
    "\n",
    "news_train, news_test, label_train, label_test = train_test_split(news[[\"title\",\"content\"]], news[\"label\"], test_size=0.33, \n",
    "                                                                  random_state=42)\n",
    "print(\" Train Dataset of size: %i \\n Test Dataset of size: %i\" % (news_train.shape[0], news_test.shape[0]))\n",
    "print(\"Size of FakeNews: %i \\n Size of Real News: %i\" % (news[news.label == 'fake'].shape[0],news[news.label==\"real\"].shape[0]))\n",
    "print(\"FakeNews Anteil:\",len(news[news.label=='fake'])/len(news))\n",
    "news_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vergleichsanalyse:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klassifizierung anhand eines Splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_len_real  =  [len(c) for c in news[news['label']=='real'].content]\n",
    "plt.hist(text_len_real,color=\"b\", bins=500,density=True,alpha=0.4,label=\"real\")\n",
    "text_len_fake = [len(c) for c in news[news['label']=='fake'].content]\n",
    "plt.hist(text_len_fake,color=\"r\",bins=500, density=True,alpha=0.4,label=\"fake\")\n",
    "plt.xlim(0,20000)\n",
    "plt.xlabel(\"Textlänge\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"x\": text_len_fake+text_len_real, \"truth\": [0]*len(text_len_fake) + [1]*len(text_len_real)})\n",
    "split=2500\n",
    "plt.vlines(split,0,0.00025)\n",
    "plt.hist(text_len_real,color=\"b\", bins=500,density=True,alpha=0.4,label=\"real\")\n",
    "plt.hist(text_len_fake,color=\"r\",bins=500, density=True,alpha=0.4,label=\"fake\")\n",
    "plt.xlim(0,20000)\n",
    "plt.xlabel(\"Textlänge\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.multiclass import unique_labels\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"predict\"] = data.x > split\n",
    "data.head()\n",
    "from sklearn.metrics import confusion_matrix\n",
    "data = data.replace(0,\"fake\").replace(1,\"real\").replace(False,\"fake\").replace(True,\"real\")\n",
    "plot_confusion_matrix(data.truth,data.predict,[\"fake\",\"truth\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using BERT for Datapreprocessing\n",
    "## Encode Titles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = BertClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8f2c92b5dd91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_title_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnews_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.7/site-packages/bert_serving/client/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ip, port, port_out, output_fmt, show_server_config, identity, check_version, check_length, check_token_info, ignore_all_checks, timeout)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignore_all_checks\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcheck_version\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mshow_server_config\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcheck_length\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcheck_token_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0ms_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_status\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcheck_version\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0ms_status\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'server_version'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'client_version'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.7/site-packages/bert_serving/client/__init__.py\u001b[0m in \u001b[0;36marg_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreceiver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetsockopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRCVTIMEO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_e\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                 t_e = TimeoutError(\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.7/site-packages/bert_serving/client/__init__.py\u001b[0m in \u001b[0;36mserver_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \"\"\"\n\u001b[1;32m    231\u001b[0m         \u001b[0mreq_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'SHOW_CONFIG'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mjsonapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.7/site-packages/bert_serving/client/__init__.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, wait_for_req_id)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0;31m# receive a response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreceiver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m                 \u001b[0mrequest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.7/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0many\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreasons\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mSocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mmight\u001b[0m \u001b[0mfail\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \"\"\"\n\u001b[0;32m--> 470\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsockopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRCVMORE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/anaconda3/lib/python3.7/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_title_enc = bc.encode(list(news_train['title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('encode_news.h5', 'w') as hf:\n",
    "    hf.create_dataset(\"train_title_encode\",  train_title_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_title_enc = bc.encode(list(news_test['title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('encode_news.h5', 'w') as hf:\n",
    "    hf.create_dataset(\"test_title_encode\",  test_title_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/larsmoellerherm/.local/anaconda3/lib/python3.7/site-packages/bert_serving/client/__init__.py:277: UserWarning: server does not put a restriction on \"max_seq_len\", it will determine \"max_seq_len\" dynamically according to the sequences in the batch. you can restrict the sequence length on the client side for better efficiency\n",
      "  warnings.warn('server does not put a restriction on \"max_seq_len\", '\n"
     ]
    }
   ],
   "source": [
    "content = []\n",
    "num_sentences_train = []\n",
    "for c in news_train['content']:\n",
    "    tok = tokenize.sent_tokenize(c)\n",
    "    content  = content + tok\n",
    "    num_sentences_train.append(len(tok))\n",
    "\n",
    "train_content_encode = bc.encode(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('encode_news.h5', 'a') as hf:\n",
    "    hf.create_dataset(\"train_content_encode\",  data = train_content_encode)\n",
    "    hf.create_dataset(\"train_num_sentences\", data = np.array(num_sentences_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = []\n",
    "num_sentences_test = []\n",
    "for c in news_test['content']:\n",
    "    tok = tokenize.sent_tokenize(c)\n",
    "    content  = content + tok\n",
    "    num_sentences_test.append(len(tok))\n",
    "\n",
    "test_content_encode = bc.encode(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('encode_news.h5', 'a') as hf:\n",
    "    hf.create_dataset(\"test_content_encode\",  data = test_content_encode)\n",
    "    hf.create_dataset(\"test_num_sentences\", data = np.array(num_sentences_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read encoded data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('title_encode.h5', 'r') as hf:\n",
    "    title_encode = hf['title_encode'][:]\n",
    "    #text_encode = hf['text_encode'][:]\n",
    "    #num_sentences = hf['num_sentences'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preparing for NN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_NN = pd.DataFrame(data = title_encode)\n",
    "title_NN.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verkleinerung des Designspace mithilfe einer PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modell = PCA()\n",
    "modell.fit(title_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(768),np.cumsum(modell.explained_variance_ratio_))\n",
    "plt.xlabel(\"Hauptkomponente\")\n",
    "plt.ylabel(\"Kummulierte Varianz\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es gibt drei Methoden, um zu entscheiden wie viele Hauptkomponenten ausreichend sind:\n",
    "\n",
    "1. Methode: eine bestimmter prozentsatz der Varainz soll erklärt sein:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Anzahl der Hauptkomponenten für erklärte Varianz größer 0.8: \", sum(np.cumsum(modell.explained_variance_ratio_)<0.8)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Methode: Die Hauptkomponenten, die mehr als die mittlere Varianz erkären"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Anzahl der Hauptkomponenten größer der mittleren erklärten Varainz: \",sum(modell.explained_variance_ratio_ > np.mean(modell.explained_variance_ratio_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nutzen des Scree-Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(768),modell.explained_variance_ratio_)\n",
    "plt.xlabel(\"Hauptkomponente\")\n",
    "plt.ylabel(\"erklärte Varianz\")\n",
    "plt.xlim(0,200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Scree-Plot legt nahe $50-75$ Hauptkomponenten zu nutzen. Ab dann flacht der Graph sehr stark ab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
