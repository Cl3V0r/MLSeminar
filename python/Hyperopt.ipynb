{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization mit hyperas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import seaborn as sn\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LeakyReLU, Activation\n",
    "from keras.regularizers import l2, l1\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform, normal, qlognormal, randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How are the Hyperparameter distributed\n",
    "\n",
    "## Strukture\n",
    "\n",
    "size of first and second hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.round(np.random.lognormal(7,0.5,10000)/10)*10\n",
    "plt.hist(x,bins=100)\n",
    "plt.xlim(0,5000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "size of third hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.round(np.random.lognormal(4,0.5,10000)/1)*1\n",
    "plt.hist(x,bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =np.random.uniform(0,0.1,10000)\n",
    "plt.hist(x,bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_bow():\n",
    "    x_test = np.genfromtxt(\"../build/preprocessed/bow_X_test.txt\")\n",
    "    x_train = np.genfromtxt(\"../build/preprocessed/bow_X_train.txt\")\n",
    "    y_test = np.genfromtxt(\"../build/preprocessed/bow_y_test.txt\")\n",
    "    y_train = np.genfromtxt(\"../build/preprocessed/bow_y_train.txt\")\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_structure(x_train, y_train, x_test, y_test):\n",
    "    dim = x_train.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(Dense({{qlognormal(7,0.5,10)}}, input_dim=dim))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    if {{choice(['three', 'four'])}} == 'four':\n",
    "        model.add(Dense({{qlognormal(7,0.5,10)}}))\n",
    "        model.add(Activation('relu'))\n",
    "        \n",
    "    model.add(Dense({{qlognormal(4,0.5,1)}}))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', metrics=['accuracy'],\n",
    "                  optimizer='adam')\n",
    "\n",
    "    result = model.fit(x_train, y_train,\n",
    "              batch_size=64,\n",
    "              epochs=30,\n",
    "              verbose=2,\n",
    "              validation_split=0.3)\n",
    "    validation_acc = np.amax(result.history['val_acc']) \n",
    "    print('Best validation acc of epoch:', validation_acc)\n",
    "    return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(x_train, y_train, x_test, y_test):\n",
    "    dim = x_train.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(int(np.abs(1187.5872913047178)), input_dim=dim))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(int(np.abs(-1475.2916969518506))))\n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dense(261))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss={{choice(['hinge','binary_crossentropy','squared_hinge'])}}, metrics=['accuracy'],\n",
    "                  optimizer={{choice(['adam','AdaDelta','Adagrad'])}})\n",
    "\n",
    "    result = model.fit(x_train, y_train,\n",
    "              batch_size=64,\n",
    "              epochs=30,\n",
    "              verbose=2,\n",
    "              validation_split=0.3)\n",
    "    validation_acc = np.amax(result.history['val_acc']) \n",
    "    print('Best validation acc of epoch:', validation_acc)\n",
    "    return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_regularization(x_train, y_train, x_test, y_test):\n",
    "    dim = x_train.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(int(np.abs(1187.5872913047178)), kernel_regularizer=l1({{uniform(0,0.1)}}), input_dim=dim))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(int(np.abs(-1475.2916969518506)),kernel_regularizer=l2({{uniform(0,0.1)}})))\n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dense(261,kernel_regularizer=l2({{uniform(0,0.1)}})))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', metrics=['accuracy'],\n",
    "                  optimizer='Adagrad')\n",
    "\n",
    "    result = model.fit(x_train, y_train,\n",
    "              batch_size=64,\n",
    "              epochs=30,\n",
    "              verbose=2,\n",
    "              validation_split=0.3)\n",
    "    validation_acc = np.amax(result.history['val_acc']) \n",
    "    print('Best validation acc of epoch:', validation_acc)\n",
    "    return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization with hyperopt\n",
    "Algorithm: Tree of Parzen Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "best_run, best_model = optim.minimize(model=model_structure,\n",
    "                                      data=data_bow,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=50,\n",
    "                                      trials=trials,\n",
    "                                     notebook_name='Hyperopt')\n",
    "print(\"Best performing model chosen hyper-parameters:\")\n",
    "print(best_run)\n",
    "best_model.save('../model/best_Hyperopt_NN_bow_struct.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "best_run, best_model = optim.minimize(model=model_training,\n",
    "                                      data=data_bow,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=15,\n",
    "                                      trials=trials,\n",
    "                                     notebook_name='Hyperopt')\n",
    "print(\"Best performing model chosen hyper-parameters:\")\n",
    "print(best_run)\n",
    "best_model.save('../model/best_Hyperopt_NN_bow_training.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "best_run, best_model = optim.minimize(model=model_regularization,\n",
    "                                      data=data_bow,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=80,\n",
    "                                      trials=trials,\n",
    "                                     notebook_name='Hyperopt')\n",
    "print(\"Best performing model chosen hyper-parameters:\")\n",
    "print(best_run)\n",
    "best_model.save('../model/best_Hyperopt_NN_bow_regularization.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = data_bow()\n",
    "best_model = load_model('../model/best_Hyperopt_NN_bow_regularization.hdf5')\n",
    "y_pred = best_model.predict(X_test, batch_size=64, verbose=1)\n",
    "y_pred_train = best_model.predict(X_train, batch_size=64, verbose=1)\n",
    "y_pred_bool = np.round(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train best model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(network_history):\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot(network_history.history['loss'])\n",
    "    plt.plot(network_history.history['val_loss'])\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.savefig(\"../build/plots/bow/history_bow_best.pdf\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_281 (Dense)            (None, 1187)              1188187   \n",
      "_________________________________________________________________\n",
      "activation_281 (Activation)  (None, 1187)              0         \n",
      "_________________________________________________________________\n",
      "dense_282 (Dense)            (None, 1475)              1752300   \n",
      "_________________________________________________________________\n",
      "activation_282 (Activation)  (None, 1475)              0         \n",
      "_________________________________________________________________\n",
      "dense_283 (Dense)            (None, 261)               385236    \n",
      "_________________________________________________________________\n",
      "activation_283 (Activation)  (None, 261)               0         \n",
      "_________________________________________________________________\n",
      "dense_284 (Dense)            (None, 1)                 262       \n",
      "_________________________________________________________________\n",
      "activation_284 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,325,985\n",
      "Trainable params: 3,325,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test = data_bow()\n",
    "best_model = load_model('../model/best_Hyperopt_NN_bow_regularization.hdf5')\n",
    "model = Sequential.from_config(best_model.get_config())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13659 samples, validate on 5854 samples\n",
      "Epoch 1/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 2.6207 - acc: 0.8371 - val_loss: 0.4891 - val_acc: 0.8982\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.48909, saving model to ../model/best_Hyperopt_NN_bow_trained.hdf5\n",
      "Epoch 2/100\n",
      "13659/13659 [==============================] - 18s 1ms/step - loss: 0.4392 - acc: 0.9031 - val_loss: 0.4911 - val_acc: 0.8548\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.48909\n",
      "Epoch 3/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.3796 - acc: 0.9143 - val_loss: 0.3880 - val_acc: 0.9042\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.48909 to 0.38804, saving model to ../model/best_Hyperopt_NN_bow_trained.hdf5\n",
      "Epoch 4/100\n",
      "13659/13659 [==============================] - 20s 1ms/step - loss: 0.3331 - acc: 0.9261 - val_loss: 0.3799 - val_acc: 0.9011\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.38804 to 0.37990, saving model to ../model/best_Hyperopt_NN_bow_trained.hdf5\n",
      "Epoch 5/100\n",
      "13659/13659 [==============================] - 20s 1ms/step - loss: 0.3035 - acc: 0.9359 - val_loss: 0.3641 - val_acc: 0.9050\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.37990 to 0.36405, saving model to ../model/best_Hyperopt_NN_bow_trained.hdf5\n",
      "Epoch 6/100\n",
      "13659/13659 [==============================] - 20s 1ms/step - loss: 0.2842 - acc: 0.9432 - val_loss: 0.3497 - val_acc: 0.9083\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.36405 to 0.34973, saving model to ../model/best_Hyperopt_NN_bow_trained.hdf5\n",
      "Epoch 7/100\n",
      "13659/13659 [==============================] - 21s 2ms/step - loss: 0.2669 - acc: 0.9492 - val_loss: 0.3531 - val_acc: 0.9100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.34973\n",
      "Epoch 8/100\n",
      "13659/13659 [==============================] - 20s 1ms/step - loss: 0.2525 - acc: 0.9560 - val_loss: 0.3565 - val_acc: 0.9019\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.34973\n",
      "Epoch 9/100\n",
      "13659/13659 [==============================] - 21s 2ms/step - loss: 0.2383 - acc: 0.9626 - val_loss: 0.3459 - val_acc: 0.9088\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.34973 to 0.34595, saving model to ../model/best_Hyperopt_NN_bow_trained.hdf5\n",
      "Epoch 10/100\n",
      "13659/13659 [==============================] - 20s 1ms/step - loss: 0.2267 - acc: 0.9668 - val_loss: 0.3482 - val_acc: 0.9088\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.34595\n",
      "Epoch 11/100\n",
      "13659/13659 [==============================] - 20s 1ms/step - loss: 0.2153 - acc: 0.9730 - val_loss: 0.3594 - val_acc: 0.9100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.34595\n",
      "Epoch 12/100\n",
      "13659/13659 [==============================] - 22s 2ms/step - loss: 0.2150 - acc: 0.9724 - val_loss: 0.3509 - val_acc: 0.9100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.34595\n",
      "Epoch 13/100\n",
      "13659/13659 [==============================] - 22s 2ms/step - loss: 0.2014 - acc: 0.9781 - val_loss: 0.3521 - val_acc: 0.9098\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.34595\n",
      "Epoch 14/100\n",
      "13659/13659 [==============================] - 22s 2ms/step - loss: 0.1914 - acc: 0.9813 - val_loss: 0.3498 - val_acc: 0.9093\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.34595\n",
      "Epoch 15/100\n",
      "13659/13659 [==============================] - 23s 2ms/step - loss: 0.1841 - acc: 0.9854 - val_loss: 0.3549 - val_acc: 0.9149\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.34595\n",
      "Epoch 16/100\n",
      "13659/13659 [==============================] - 24s 2ms/step - loss: 0.1793 - acc: 0.9873 - val_loss: 0.3509 - val_acc: 0.9141\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.34595\n",
      "Epoch 17/100\n",
      "13659/13659 [==============================] - 24s 2ms/step - loss: 0.1739 - acc: 0.9889 - val_loss: 0.3542 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.34595\n",
      "Epoch 18/100\n",
      "13659/13659 [==============================] - 24s 2ms/step - loss: 0.1694 - acc: 0.9896 - val_loss: 0.3419 - val_acc: 0.9125\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.34595 to 0.34193, saving model to ../model/best_Hyperopt_NN_bow_trained.hdf5\n",
      "Epoch 19/100\n",
      "13659/13659 [==============================] - 24s 2ms/step - loss: 0.1660 - acc: 0.9906 - val_loss: 0.3459 - val_acc: 0.9158\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.34193\n",
      "Epoch 20/100\n",
      "13659/13659 [==============================] - 25s 2ms/step - loss: 0.1632 - acc: 0.9912 - val_loss: 0.3469 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.34193\n",
      "Epoch 21/100\n",
      "13659/13659 [==============================] - 28s 2ms/step - loss: 0.1593 - acc: 0.9922 - val_loss: 0.3470 - val_acc: 0.9146\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.34193\n",
      "Epoch 22/100\n",
      "13659/13659 [==============================] - 27s 2ms/step - loss: 0.1564 - acc: 0.9922 - val_loss: 0.3506 - val_acc: 0.9148\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.34193\n",
      "Epoch 23/100\n",
      "13659/13659 [==============================] - 25s 2ms/step - loss: 0.1533 - acc: 0.9924 - val_loss: 0.3502 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.34193\n",
      "Epoch 24/100\n",
      "13659/13659 [==============================] - 24s 2ms/step - loss: 0.1511 - acc: 0.9932 - val_loss: 0.3467 - val_acc: 0.9146\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.34193\n",
      "Epoch 25/100\n",
      "13659/13659 [==============================] - 23s 2ms/step - loss: 0.1488 - acc: 0.9934 - val_loss: 0.3499 - val_acc: 0.9129\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.34193\n",
      "Epoch 26/100\n",
      "13659/13659 [==============================] - 22s 2ms/step - loss: 0.1465 - acc: 0.9941 - val_loss: 0.3457 - val_acc: 0.9125\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.34193\n",
      "Epoch 27/100\n",
      "13659/13659 [==============================] - 21s 2ms/step - loss: 0.1445 - acc: 0.9942 - val_loss: 0.3453 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.34193\n",
      "Epoch 28/100\n",
      "13659/13659 [==============================] - 23s 2ms/step - loss: 0.1426 - acc: 0.9944 - val_loss: 0.3483 - val_acc: 0.9105\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.34193\n",
      "Epoch 29/100\n",
      "13659/13659 [==============================] - 24s 2ms/step - loss: 0.1409 - acc: 0.9941 - val_loss: 0.3451 - val_acc: 0.9170\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.34193\n",
      "Epoch 30/100\n",
      "13659/13659 [==============================] - 26s 2ms/step - loss: 0.1396 - acc: 0.9950 - val_loss: 0.3418 - val_acc: 0.9158\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.34193 to 0.34175, saving model to ../model/best_Hyperopt_NN_bow_trained.hdf5\n",
      "Epoch 31/100\n",
      "13659/13659 [==============================] - 20s 1ms/step - loss: 0.1378 - acc: 0.9951 - val_loss: 0.3421 - val_acc: 0.9154\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.34175\n",
      "Epoch 32/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1364 - acc: 0.9951 - val_loss: 0.3427 - val_acc: 0.9161\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.34175\n",
      "Epoch 33/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1349 - acc: 0.9955 - val_loss: 0.3468 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.34175\n",
      "Epoch 34/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1337 - acc: 0.9958 - val_loss: 0.3434 - val_acc: 0.9139\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.34175\n",
      "Epoch 35/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1325 - acc: 0.9956 - val_loss: 0.3432 - val_acc: 0.9134\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.34175\n",
      "Epoch 36/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1312 - acc: 0.9958 - val_loss: 0.3428 - val_acc: 0.9132\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.34175\n",
      "Epoch 37/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1299 - acc: 0.9957 - val_loss: 0.3502 - val_acc: 0.9166\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.34175\n",
      "Epoch 38/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1291 - acc: 0.9963 - val_loss: 0.3467 - val_acc: 0.9141\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.34175\n",
      "Epoch 39/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1281 - acc: 0.9963 - val_loss: 0.3454 - val_acc: 0.9149\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.34175\n",
      "Epoch 40/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1271 - acc: 0.9963 - val_loss: 0.3456 - val_acc: 0.9168\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.34175\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13659/13659 [==============================] - 18s 1ms/step - loss: 0.1263 - acc: 0.9966 - val_loss: 0.3436 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.34175\n",
      "Epoch 42/100\n",
      "13659/13659 [==============================] - 18s 1ms/step - loss: 0.1252 - acc: 0.9963 - val_loss: 0.3402 - val_acc: 0.9154\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.34175 to 0.34018, saving model to ../model/best_Hyperopt_NN_bow_trained.hdf5\n",
      "Epoch 43/100\n",
      "13659/13659 [==============================] - 18s 1ms/step - loss: 0.1244 - acc: 0.9967 - val_loss: 0.3440 - val_acc: 0.9156\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.34018\n",
      "Epoch 44/100\n",
      "13659/13659 [==============================] - 18s 1ms/step - loss: 0.1236 - acc: 0.9966 - val_loss: 0.3431 - val_acc: 0.9161\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.34018\n",
      "Epoch 45/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1227 - acc: 0.9969 - val_loss: 0.3462 - val_acc: 0.9156\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.34018\n",
      "Epoch 46/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1220 - acc: 0.9968 - val_loss: 0.3430 - val_acc: 0.9154\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.34018\n",
      "Epoch 47/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1211 - acc: 0.9968 - val_loss: 0.3404 - val_acc: 0.9170\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.34018\n",
      "Epoch 48/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1203 - acc: 0.9969 - val_loss: 0.3385 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.34018 to 0.33850, saving model to ../model/best_Hyperopt_NN_bow_trained.hdf5\n",
      "Epoch 49/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1196 - acc: 0.9971 - val_loss: 0.3424 - val_acc: 0.9166\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.33850\n",
      "Epoch 50/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1187 - acc: 0.9974 - val_loss: 0.3427 - val_acc: 0.9154\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.33850\n",
      "Epoch 51/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1181 - acc: 0.9971 - val_loss: 0.3432 - val_acc: 0.9158\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.33850\n",
      "Epoch 52/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1176 - acc: 0.9972 - val_loss: 0.3395 - val_acc: 0.9165\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.33850\n",
      "Epoch 53/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1169 - acc: 0.9972 - val_loss: 0.3407 - val_acc: 0.9160\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.33850\n",
      "Epoch 54/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1163 - acc: 0.9971 - val_loss: 0.3382 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.33850 to 0.33821, saving model to ../model/best_Hyperopt_NN_bow_trained.hdf5\n",
      "Epoch 55/100\n",
      "13659/13659 [==============================] - 20s 1ms/step - loss: 0.1158 - acc: 0.9972 - val_loss: 0.3413 - val_acc: 0.9141\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.33821\n",
      "Epoch 56/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1151 - acc: 0.9975 - val_loss: 0.3359 - val_acc: 0.9173\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.33821 to 0.33586, saving model to ../model/best_Hyperopt_NN_bow_trained.hdf5\n",
      "Epoch 57/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1145 - acc: 0.9975 - val_loss: 0.3428 - val_acc: 0.9149\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.33586\n",
      "Epoch 58/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1139 - acc: 0.9974 - val_loss: 0.3378 - val_acc: 0.9158\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.33586\n",
      "Epoch 59/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1134 - acc: 0.9976 - val_loss: 0.3408 - val_acc: 0.9146\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.33586\n",
      "Epoch 60/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1128 - acc: 0.9977 - val_loss: 0.3428 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.33586\n",
      "Epoch 61/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1123 - acc: 0.9979 - val_loss: 0.3395 - val_acc: 0.9156\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.33586\n",
      "Epoch 62/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1118 - acc: 0.9977 - val_loss: 0.3368 - val_acc: 0.9158\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.33586\n",
      "Epoch 63/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1113 - acc: 0.9979 - val_loss: 0.3392 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.33586\n",
      "Epoch 64/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1108 - acc: 0.9977 - val_loss: 0.3376 - val_acc: 0.9165\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.33586\n",
      "Epoch 65/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1103 - acc: 0.9980 - val_loss: 0.3373 - val_acc: 0.9156\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.33586\n",
      "Epoch 66/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1098 - acc: 0.9981 - val_loss: 0.3376 - val_acc: 0.9154\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.33586\n",
      "Epoch 67/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1094 - acc: 0.9980 - val_loss: 0.3369 - val_acc: 0.9149\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.33586\n",
      "Epoch 68/100\n",
      "13659/13659 [==============================] - 20s 1ms/step - loss: 0.1088 - acc: 0.9982 - val_loss: 0.3374 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.33586\n",
      "Epoch 69/100\n",
      "13659/13659 [==============================] - 20s 1ms/step - loss: 0.1084 - acc: 0.9978 - val_loss: 0.3387 - val_acc: 0.9168\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.33586\n",
      "Epoch 70/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1080 - acc: 0.9980 - val_loss: 0.3392 - val_acc: 0.9165\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.33586\n",
      "Epoch 71/100\n",
      "13659/13659 [==============================] - 20s 1ms/step - loss: 0.1075 - acc: 0.9980 - val_loss: 0.3401 - val_acc: 0.9166\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.33586\n",
      "Epoch 72/100\n",
      "13659/13659 [==============================] - 20s 1ms/step - loss: 0.1071 - acc: 0.9982 - val_loss: 0.3403 - val_acc: 0.9144\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.33586\n",
      "Epoch 73/100\n",
      "13659/13659 [==============================] - 20s 1ms/step - loss: 0.1066 - acc: 0.9982 - val_loss: 0.3378 - val_acc: 0.9151\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.33586\n",
      "Epoch 74/100\n",
      "13659/13659 [==============================] - 20s 1ms/step - loss: 0.1062 - acc: 0.9983 - val_loss: 0.3450 - val_acc: 0.9132\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.33586\n",
      "Epoch 75/100\n",
      "13659/13659 [==============================] - 20s 1ms/step - loss: 0.1059 - acc: 0.9982 - val_loss: 0.3372 - val_acc: 0.9165\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33586\n",
      "Epoch 76/100\n",
      "13659/13659 [==============================] - 20s 1ms/step - loss: 0.1054 - acc: 0.9980 - val_loss: 0.3364 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.33586\n",
      "Epoch 77/100\n",
      "13659/13659 [==============================] - 20s 1ms/step - loss: 0.1050 - acc: 0.9982 - val_loss: 0.3335 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.33586 to 0.33351, saving model to ../model/best_Hyperopt_NN_bow_trained.hdf5\n",
      "Epoch 78/100\n",
      "13659/13659 [==============================] - 20s 1ms/step - loss: 0.1047 - acc: 0.9982 - val_loss: 0.3366 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.33351\n",
      "Epoch 79/100\n",
      "13659/13659 [==============================] - 20s 1ms/step - loss: 0.1043 - acc: 0.9981 - val_loss: 0.3373 - val_acc: 0.9139\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33351\n",
      "Epoch 80/100\n",
      "13659/13659 [==============================] - 20s 1ms/step - loss: 0.1039 - acc: 0.9983 - val_loss: 0.3394 - val_acc: 0.9144\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.33351\n",
      "Epoch 81/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1034 - acc: 0.9982 - val_loss: 0.3371 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33351\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1032 - acc: 0.9983 - val_loss: 0.3370 - val_acc: 0.9168\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33351\n",
      "Epoch 83/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1028 - acc: 0.9982 - val_loss: 0.3370 - val_acc: 0.9154\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33351\n",
      "Epoch 84/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1024 - acc: 0.9983 - val_loss: 0.3348 - val_acc: 0.9142\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33351\n",
      "Epoch 85/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1021 - acc: 0.9982 - val_loss: 0.3341 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33351\n",
      "Epoch 86/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1018 - acc: 0.9982 - val_loss: 0.3349 - val_acc: 0.9148\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33351\n",
      "Epoch 87/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1014 - acc: 0.9983 - val_loss: 0.3336 - val_acc: 0.9154\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33351\n",
      "Epoch 88/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1011 - acc: 0.9984 - val_loss: 0.3326 - val_acc: 0.9146\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.33351 to 0.33260, saving model to ../model/best_Hyperopt_NN_bow_trained.hdf5\n",
      "Epoch 89/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1007 - acc: 0.9983 - val_loss: 0.3386 - val_acc: 0.9160\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33260\n",
      "Epoch 90/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1005 - acc: 0.9983 - val_loss: 0.3335 - val_acc: 0.9156\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33260\n",
      "Epoch 91/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.1001 - acc: 0.9983 - val_loss: 0.3350 - val_acc: 0.9153\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33260\n",
      "Epoch 92/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.0998 - acc: 0.9983 - val_loss: 0.3343 - val_acc: 0.9165\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33260\n",
      "Epoch 93/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.0996 - acc: 0.9984 - val_loss: 0.3336 - val_acc: 0.9151\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33260\n",
      "Epoch 94/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.0992 - acc: 0.9983 - val_loss: 0.3314 - val_acc: 0.9149\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.33260 to 0.33141, saving model to ../model/best_Hyperopt_NN_bow_trained.hdf5\n",
      "Epoch 95/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.0989 - acc: 0.9984 - val_loss: 0.3393 - val_acc: 0.9149\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33141\n",
      "Epoch 96/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.0986 - acc: 0.9984 - val_loss: 0.3295 - val_acc: 0.9154\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.33141 to 0.32954, saving model to ../model/best_Hyperopt_NN_bow_trained.hdf5\n",
      "Epoch 97/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.0983 - acc: 0.9985 - val_loss: 0.3420 - val_acc: 0.9107\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.32954\n",
      "Epoch 98/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.0981 - acc: 0.9984 - val_loss: 0.3369 - val_acc: 0.9170\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.32954\n",
      "Epoch 99/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.0977 - acc: 0.9983 - val_loss: 0.3445 - val_acc: 0.9148\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.32954\n",
      "Epoch 100/100\n",
      "13659/13659 [==============================] - 19s 1ms/step - loss: 0.0975 - acc: 0.9985 - val_loss: 0.3334 - val_acc: 0.9146\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.32954\n"
     ]
    }
   ],
   "source": [
    "filepath = '../model/best_Hyperopt_NN_bow_trained.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='Adagrad',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train, validation_split=0.3,\n",
    "                    epochs=100,batch_size=64, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8364/8364 [==============================] - 2s 240us/step\n",
      "19513/19513 [==============================] - 4s 215us/step\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('../model/best_Hyperopt_NN_bow_trained.hdf5')\n",
    "y_pred = best_model.predict(X_test, batch_size=64, verbose=1)\n",
    "y_pred_train = best_model.predict(X_train, batch_size=64, verbose=1)\n",
    "y_pred_bool = np.round(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.91      0.90      3650\n",
      "         1.0       0.93      0.92      0.92      4714\n",
      "\n",
      "   micro avg       0.92      0.92      0.92      8364\n",
      "   macro avg       0.91      0.91      0.91      8364\n",
      "weighted avg       0.92      0.92      0.92      8364\n",
      "\n",
      "[[3324  326]\n",
      " [ 381 4333]]\n",
      "Predicted   0.0   1.0\n",
      "Actual               \n",
      "0.0        3324   326\n",
      "1.0         381  4333\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, y_pred_bool))\n",
    "print(confusion_matrix(Y_test, y_pred_bool,labels=[0,1]))\n",
    "\n",
    "#Confusion Matrix\n",
    "cnfn_matrix = pd.crosstab(Y_test, y_pred_bool[:,0], rownames=['Actual'], colnames=['Predicted'])\n",
    "print(cnfn_matrix)\n",
    "cnfn_matrix.columns = ['fake','real']\n",
    "cnfn_matrix = cnfn_matrix.rename_axis(\"Predicted\", axis=\"columns\")\n",
    "cnfn_matrix.rename(index = {0.0: \"fake\", 1.0:'real'}, inplace = True) \n",
    "cnfn_matrix = cnfn_matrix/Y_test.shape[0]\n",
    "sn.heatmap(cnfn_matrix, annot=True , cmap='viridis')\n",
    "#plt.show()\n",
    "plt.savefig(\"../build/plots/bow/cnfsn_mtx_bow_best_nn.pdf\")\n",
    "plt.close()\n",
    "\n",
    "#Overtraining test\n",
    "plt.hist(y_pred[Y_test == 0],label=\"fake test\", alpha = 0.4, color = \"r\",density=True)\n",
    "plt.hist(y_pred_train[Y_train == 0],label='fake train', alpha = 0.4, color = 'r', histtype='step',density=True)\n",
    "plt.hist(y_pred[Y_test == 1],label = \"real test\",alpha = 0.4, color = \"b\",density=True)\n",
    "plt.hist(y_pred_train[Y_train == 1],label='real train', alpha = 0.4, color = 'b', histtype='step',density=True)\n",
    "\n",
    "plt.xlabel(\"Prediction Probability\")\n",
    "plt.ylabel(\"density\")\n",
    "plt.legend(loc='upper center')\n",
    "#plt.show()\n",
    "plt.savefig(\"../build/plots/bow/prob_bow_best_nn.pdf\")\n",
    "plt.close()\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "fpr, tpr, _ = roc_curve(Y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.show()\n",
    "plt.savefig(\"../build/plots/bow/roc_Hyperopt_bow_best_nn.pdf\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation\n",
    "\n",
    "### Wordclkoud confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'prediction':y_pred[:,0],'prediction_bool':y_pred_bool[:,0],'truth':Y_test})\n",
    "results['dist'] = np.abs(results.truth - results.prediction)\n",
    "results = results.sort_values('dist',axis=0,ascending=False)\n",
    "FP = results[(results.prediction_bool== 1) & (results.truth == 0)]\n",
    "FN = results[(results.prediction_bool== 0) & (results.truth == 1)]\n",
    "TP = results[(results.prediction_bool== 1) & (results.truth == 1)]\n",
    "TN = results[(results.prediction_bool== 0) & (results.truth == 0)]\n",
    "X_test = pd.DataFrame(X_test)\n",
    "X_FP = X_test.loc[FP.index]\n",
    "X_FN = X_test.loc[FN.index]\n",
    "X_TP = X_test.loc[TP.index]\n",
    "X_TN = X_test.loc[TN.index]\n",
    "f = open(\"../build/preprocessed/bow_feature_names.txt\", \"r\")\n",
    "words = [x[:-1] for x in f]\n",
    "X_FP.columns = words\n",
    "X_FN.columns = words\n",
    "X_TP.columns = words\n",
    "X_TN.columns = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "from PIL import Image\n",
    "from PIL import ImageFilter\n",
    "def plotWordcloud_cnfn(TN,FN,FP,TP):    \n",
    "    TN = TN.sum().to_dict()\n",
    "    FN = FN.sum().to_dict()\n",
    "    FP = FP.sum().to_dict()\n",
    "    TP = TP.sum().to_dict()\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,10),dpi=100)\n",
    "\n",
    "    plt.subplot(2, 2, 1)\n",
    "    wordcloud = WordCloud(background_color='black',\n",
    "                          width=1920,\n",
    "                          height=1080,\n",
    "                          mask=np.array(Image.open('../data/pictures/trump_silhouette.png'))\n",
    "                          ).generate_from_frequencies(TN)\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.margins(x=0, y=0)\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    wordcloud = WordCloud(background_color='black',\n",
    "                          width=1920,\n",
    "                          height=1080,\n",
    "                          mask= np.array(Image.open('../data/pictures/trump_silhouette.png'))\n",
    "                          ).generate_from_frequencies(FP)\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.margins(x=0, y=0)\n",
    "\n",
    "    plt.subplot(2, 2, 3)\n",
    "    wordcloud = WordCloud(background_color='black',\n",
    "                          width=1920,\n",
    "                          height=1080,\n",
    "                          mask=np.array(Image.open('../data/pictures/USA.jpg'))\n",
    "                          ).generate_from_frequencies(FN)\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.margins(x=0, y=0)\n",
    "\n",
    "    plt.subplot(2, 2, 4)\n",
    "    wordcloud = WordCloud(background_color='black',\n",
    "                          width=1920,\n",
    "                          height=1080,\n",
    "                          mask=np.array(Image.open('../data/pictures/USA.jpg'))\n",
    "                          ).generate_from_frequencies(TP)\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.margins(x=0, y=0)\n",
    "\n",
    "    #plt.show()\n",
    "    plt.savefig(\"../build/plots/bow/cnfn_wordcloud.pdf\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotWordcloud_cnfn(X_TN,X_FN,X_FP,X_TP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordcloud fake real news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotWordcloud(content,t):\n",
    "    if(t!=\"\"):\n",
    "       mask = np.array(Image.open('../data/pictures/'+t))\n",
    "    else:\n",
    "        mask=None\n",
    "        \n",
    "\n",
    "    content = content.sum().to_dict()\n",
    "    wordcloud = WordCloud(background_color='black',\n",
    "                      width=1920,\n",
    "                      height=1080,\n",
    "                      mask=mask\n",
    "                      ).generate_from_frequencies(content)\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.margins(x=0, y=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.append(X_test,X_train,axis=0)\n",
    "y = np.append(Y_test,Y_train,axis=0)\n",
    "X = pd.DataFrame(X)\n",
    "X.columns = words\n",
    "plotWordcloud(X[y==0],\"trump_silhouette.png\")\n",
    "plt.savefig(\"../build/plots/fake_wordcloud.pdf\")\n",
    "plt.close()\n",
    "plotWordcloud(X[y==1],\"USA.jpg\")\n",
    "plt.savefig(\"../build/plots/real_wordcloud.pdf\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Untersuchung der first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_weights = best_model.layers[0].get_weights()[0]\n",
    "first_weights = pd.DataFrame(first_weights.transpose())\n",
    "first_weights.columns = words\n",
    "first_weightabs = np.abs(first_weights)\n",
    "first_weightsum = first_weightabs.sum(axis=0)\n",
    "content = np.abs(first_weightsum).to_dict()\n",
    "wordcloud = WordCloud(background_color='black',\n",
    "                      width=1920,\n",
    "                      height=1080\n",
    "                      ).generate_from_frequencies(content)\n",
    "plt.figure(dpi=100)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.margins(x=0, y=0)\n",
    "#plt.show()\n",
    "plt.savefig(\"../build/plots/bow/weights_wordcloud.pdf\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der offset wird nicht mitbetrachtet und macht wahrscheinlich eh keinen Sinn, zu betrachten ob es positiv oder negativ wirkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sorted_weightsum = first_weightsum.sort_values()\n",
    "neg_weights = first_weights[sorted_weightsum[:5].index]\n",
    "pos_weights = first_weights[sorted_weightsum[-5:].index]\n",
    "plot_weights = pd.concat([neg_weights,pos_weights],axis=1)\n",
    "plot_weights.plot(kind='box')\n",
    "plt.save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.read_csv('../data/mixed_news/news_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news[news.label=='fake'].iloc[0].content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
