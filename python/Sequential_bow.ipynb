{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimierung und Evaluierung des Sequential bow Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import seaborn as sn\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LeakyReLU, Activation\n",
    "from keras.regularizers import l2, l1\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adagrad\n",
    "\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform, normal, qlognormal, randint\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from PIL import Image\n",
    "from PIL import ImageFilter\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = pd.read_hdf(\"../build/preprocessed/bow_data_500.hdf5\",key=\"test\")\n",
    "x_train = pd.read_hdf(\"../build/preprocessed/bow_data_500.hdf5\",key=\"train\")\n",
    "y_test = x_test.label\n",
    "y_train = x_train.label\n",
    "x_test= x_test.drop('label',axis=1)\n",
    "x_train = x_train.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = x_train.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(1770, kernel_regularizer=l1(2.0036577552673407e-06), input_dim=dim))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(9,kernel_regularizer=l2(0.05407632514834404)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'],\n",
    "\n",
    "            optimizer='Adagrad')\n",
    "\n",
    "model.summary()\n",
    "    \n",
    "result = model.fit(x_train.values, y_train.values,\n",
    "                    batch_size=64,\n",
    "                    epochs=100,\n",
    "                    verbose=2,\n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(network_history):\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot(network_history.history['loss'])\n",
    "    plt.plot(network_history.history['val_loss'])\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "plot_history(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse des Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = pd.read_hdf(\"../build/preprocessed/bow_data_500.hdf5\",key=\"test\")\n",
    "x_train = pd.read_hdf(\"../build/preprocessed/bow_data_500.hdf5\",key=\"train\")\n",
    "X = x_test.append(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$max\\left(\\frac{(\\bar{w_1}-\\bar{w_2})^2}{s_1^2+s_2^2}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_real = X[X.label==1].mean()\n",
    "mu_fake = X[X.label==0].mean()\n",
    "sorted_words = ((mu_real-mu_fake)**2/(np.var(X[X.label==1])**2 + np.var(X[X.label==0])**2)).sort_values(ascending=False).index\n",
    "\n",
    "words_plot = pd.DataFrame({'fake':X[X.label==0][sorted_words[1:11]].mean(),'real':X[X.label==1][sorted_words[1:11]].mean()})\n",
    "words_plot.plot(kind='bar')\n",
    "plt.ylabel(r\"$\\overline{w}$\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"../build/plots/data_visualisation.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.read_csv('../data/mixed_news/news_dataset.csv')\n",
    "news = news.dropna(subset=['title','content'])\n",
    "news = news[news.content != ' ']\n",
    "news = news[news.title != ' ']\n",
    "text_len_real  =  [len(c) for c in news[news['label']=='real'].content]\n",
    "text_len_fake = [len(c) for c in news[news['label']=='fake'].content]\n",
    "print(\"Mittlere textlänge Real: \",np.mean(text_len_real))\n",
    "print(\"Mittlere Textlänge Fake: \",np.mean(text_len_fake))\n",
    "print(\"Real ist %d länger wie Fake: \" % (np.mean(text_len_real)-np.mean(text_len_fake)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How could the Hyperparameter be distributed\n",
    "\n",
    "### Strukture\n",
    "\n",
    "Größe der ersten und zweiten hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.round(np.random.lognormal(6,0.5,10000)/10)*10\n",
    "plt.hist(x,bins=100)\n",
    "plt.xlim(0,5000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Größer der dritten hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.round(np.random.lognormal(4,0.5,10000)/1)*1\n",
    "plt.hist(x,bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =np.random.uniform(0,0.1,10000)\n",
    "plt.hist(x,bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_bow():\n",
    "    x_test = pd.read_hdf(\"../build/preprocessed/bow_data_500.hdf5\",key=\"test\")\n",
    "    x_train = pd.read_hdf(\"../build/preprocessed/bow_data_500.hdf5\",key=\"train\")\n",
    "    y_test = x_test.label\n",
    "    y_train = x_train.label\n",
    "    x_test= x_test.drop('label',axis=1)\n",
    "    x_train = x_train.drop('label',axis=1)\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_structure(x_train, y_train, x_test, y_test):\n",
    "    dim = x_train.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(int({{qlognormal(6,0.5,10)}}), input_dim=dim))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    if {{choice(['three', 'four'])}} == 'four':\n",
    "        model.add(Dense(int({{qlognormal(6,0.5,10)}})))\n",
    "        model.add(Activation('relu'))\n",
    "        \n",
    "    model.add(Dense(int({{qlognormal(4,0.5,1)}})))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', metrics=['accuracy'],\n",
    "                  optimizer='adam')\n",
    "\n",
    "    result = model.fit(x_train.values, y_train.values,\n",
    "              batch_size=64,\n",
    "              epochs=30,\n",
    "              verbose=2,\n",
    "              validation_split=0.3)\n",
    "    validation_acc = np.amax(result.history['val_acc']) \n",
    "    print('Best validation acc of epoch:', validation_acc)\n",
    "    return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(x_train, y_train, x_test, y_test):\n",
    "    dim = x_train.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1770, input_dim=dim))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(9))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss={{choice(['hinge','binary_crossentropy','squared_hinge'])}}, metrics=['accuracy'],\n",
    "                  optimizer={{choice(['adam','AdaDelta','Adagrad'])}})\n",
    "\n",
    "    result = model.fit(x_train.values, y_train.values,\n",
    "              batch_size=64,\n",
    "              epochs=30,\n",
    "              verbose=2,\n",
    "              validation_split=0.3)\n",
    "    validation_acc = np.amax(result.history['val_acc']) \n",
    "    print('Best validation acc of epoch:', validation_acc)\n",
    "    return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_regularization(x_train, y_train, x_test, y_test):\n",
    "    dim = x_train.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1770, kernel_regularizer=l1({{uniform(0,0.1)}}), input_dim=dim))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(9,kernel_regularizer=l2({{uniform(0,0.1)}})))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', metrics=['accuracy'],\n",
    "                  optimizer='Adagrad')\n",
    "\n",
    "    result = model.fit(x_train.values, y_train.values,\n",
    "                      batch_size=64,\n",
    "                      epochs=30,\n",
    "                      verbose=2,\n",
    "                      validation_split=0.3)\n",
    "    validation_acc = np.amax(result.history['val_acc']) \n",
    "    print('Best validation acc of epoch:', validation_acc)\n",
    "    return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_optimizer(x_train, y_train, x_test, y_test):\n",
    "    dim = x_train.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1770, kernel_regularizer=l1(2.0*10**(-6)), input_dim=dim))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(9,kernel_regularizer=l2(0.05407632514834404)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', metrics=['accuracy'],\n",
    "                  optimizer=Adagrad(lr={{uniform(0,1)}}, epsilon=None, decay={{uniform(0,1)}}))\n",
    "\n",
    "    result = model.fit(x_train.values, y_train.values,\n",
    "                      batch_size=64,\n",
    "                      epochs=30,\n",
    "                      verbose=2,\n",
    "                      validation_split=0.3)\n",
    "    validation_acc = np.amax(result.history['val_acc']) \n",
    "    print('Best validation acc of epoch:', validation_acc)\n",
    "    return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization with hyperopt\n",
    "Algorithm: Tree of Parzen Estimators\n",
    "Optimierung in 3 Schritten:\n",
    "    - Struktur (Tiefe (2 oder 3 hidden Layers) und Breite)\n",
    "    - Training (loss function und optimizer)\n",
    "    - Regularizierung ( L1 für die erste Layer und L2 für 2 und 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "best_run, best_model = optim.minimize(model=model_structure,\n",
    "                                      data=data_bow,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=50,\n",
    "                                      trials=trials,\n",
    "                                     notebook_name='Sequential_bow')\n",
    "print(\"Best performing model chosen hyper-parameters:\")\n",
    "print(best_run)\n",
    "best_model.save('../model/best_Hyperopt_NN_bow_struct_500.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "best_run, best_model = optim.minimize(model=model_training,\n",
    "                                      data=data_bow,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=15,\n",
    "                                      trials=trials,\n",
    "                                     notebook_name='Sequential_bow')\n",
    "print(\"Best performing model chosen hyper-parameters:\")\n",
    "print(best_run)\n",
    "best_model.save('../model/best_Hyperopt_NN_bow_training_500.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "best_run, best_model = optim.minimize(model=model_regularization,\n",
    "                                      data=data_bow,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=80,\n",
    "                                      trials=trials,\n",
    "                                     notebook_name='Sequential_bow')\n",
    "print(\"Best performing model chosen hyper-parameters:\")\n",
    "print(best_run)\n",
    "best_model.save('../model/best_Hyperopt_NN_bow_regularization_500.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import h5py\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.metrics import roc_curve, auc\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import seaborn as sn\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from wordcloud import WordCloud\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Dense, Dropout, LeakyReLU, Activation\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.regularizers import l2, l1\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.callbacks import TensorBoard, ModelCheckpoint\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import load_model\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.metrics import confusion_matrix, classification_report\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils import np_utils\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import LabelEncoder\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.callbacks import EarlyStopping\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import load_model\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.optimizers import Adagrad\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform, normal, qlognormal, randint\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from wordcloud import WordCloud\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from PIL import Image\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from PIL import ImageFilter\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.ensemble import RandomForestClassifier\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'lr': hp.uniform('lr', 0,1),\n",
      "        'lr_1': hp.uniform('lr_1', 0,1),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "  1: \n",
      "  2: x_test = pd.read_hdf(\"../build/preprocessed/bow_data_500.hdf5\",key=\"test\")\n",
      "  3: x_train = pd.read_hdf(\"../build/preprocessed/bow_data_500.hdf5\",key=\"train\")\n",
      "  4: y_test = x_test.label\n",
      "  5: y_train = x_train.label\n",
      "  6: x_test= x_test.drop('label',axis=1)\n",
      "  7: x_train = x_train.drop('label',axis=1)\n",
      "  8: \n",
      "  9: \n",
      " 10: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "  1: def keras_fmin_fnct(space):\n",
      "  2: \n",
      "  3:     dim = x_train.shape[1]\n",
      "  4:     model = Sequential()\n",
      "  5:     model.add(Dense(1770, kernel_regularizer=l1(2.0*10**(-6)), input_dim=dim))\n",
      "  6:     model.add(Activation('relu'))\n",
      "  7:     model.add(Dense(9,kernel_regularizer=l2(0.05407632514834404)))\n",
      "  8:     model.add(Activation('relu'))\n",
      "  9:     model.add(Dense(1))\n",
      " 10:     model.add(Activation('sigmoid'))\n",
      " 11: \n",
      " 12:     model.compile(loss='binary_crossentropy', metrics=['accuracy'],\n",
      " 13:                   optimizer=Adagrad(lr=space['lr'], epsilon=None, decay=space['lr_1']))\n",
      " 14: \n",
      " 15:     result = model.fit(x_train.values, y_train.values,\n",
      " 16:                       batch_size=64,\n",
      " 17:                       epochs=30,\n",
      " 18:                       verbose=2,\n",
      " 19:                       validation_split=0.3)\n",
      " 20:     validation_acc = np.amax(result.history['val_acc']) \n",
      " 21:     print('Best validation acc of epoch:', validation_acc)\n",
      " 22:     return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}\n",
      " 23: \n",
      "  0%|          | 0/100 [00:00<?, ?it/s, best loss: ?]WARNING:tensorflow:From /home/larsmoellerherm/.local/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/larsmoellerherm/.local/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 13672 samples, validate on 5860 samples     \n",
      "Epoch 1/30                                           \n",
      " - 6s - loss: 3.6562 - acc: 0.4387 - val_loss: 1.3185 - val_acc: 0.4365\n",
      "\n",
      "Epoch 2/30                                           \n",
      " - 5s - loss: 2.0368 - acc: 0.4372 - val_loss: 1.2669 - val_acc: 0.4365\n",
      "\n",
      "Epoch 3/30                                           \n",
      " - 5s - loss: 1.2638 - acc: 0.4372 - val_loss: 1.2456 - val_acc: 0.4365\n",
      "\n",
      "Epoch 4/30                                           \n",
      " - 5s - loss: 1.2390 - acc: 0.4372 - val_loss: 1.2332 - val_acc: 0.4365\n",
      "\n",
      "Epoch 5/30                                           \n",
      " - 5s - loss: 1.2288 - acc: 0.4372 - val_loss: 1.2248 - val_acc: 0.4365\n",
      "\n",
      "Epoch 6/30                                           \n",
      " - 5s - loss: 1.2217 - acc: 0.4685 - val_loss: 1.2187 - val_acc: 0.5637\n",
      "\n",
      "Epoch 7/30                                           \n",
      " - 5s - loss: 1.2163 - acc: 0.5629 - val_loss: 1.2140 - val_acc: 0.5637\n",
      "\n",
      "Epoch 8/30                                           \n",
      " - 5s - loss: 1.2121 - acc: 0.5629 - val_loss: 1.2102 - val_acc: 0.5637\n",
      "\n",
      "Epoch 9/30                                           \n",
      " - 5s - loss: 1.2086 - acc: 0.5629 - val_loss: 1.2070 - val_acc: 0.5637\n",
      "\n",
      "Epoch 10/30                                          \n",
      " - 5s - loss: 1.2057 - acc: 0.5629 - val_loss: 1.2043 - val_acc: 0.5637\n",
      "\n",
      "Epoch 11/30                                          \n",
      " - 5s - loss: 1.2032 - acc: 0.5629 - val_loss: 1.2020 - val_acc: 0.5637\n",
      "\n",
      "Epoch 12/30                                          \n",
      " - 5s - loss: 1.2010 - acc: 0.5629 - val_loss: 1.2000 - val_acc: 0.5637\n",
      "\n",
      "Epoch 13/30                                          \n",
      " - 5s - loss: 1.1991 - acc: 0.5633 - val_loss: 1.1981 - val_acc: 0.5684\n",
      "\n",
      "Epoch 14/30                                          \n",
      " - 5s - loss: 1.1971 - acc: 0.5674 - val_loss: 1.1961 - val_acc: 0.5684\n",
      "\n",
      "Epoch 15/30                                          \n",
      " - 5s - loss: 1.1953 - acc: 0.5674 - val_loss: 1.1944 - val_acc: 0.5684\n",
      "\n",
      "Epoch 16/30                                          \n",
      " - 5s - loss: 1.1938 - acc: 0.5674 - val_loss: 1.1929 - val_acc: 0.5689\n",
      "\n",
      "Epoch 17/30                                          \n",
      " - 5s - loss: 1.1923 - acc: 0.5679 - val_loss: 1.1915 - val_acc: 0.5698\n",
      "\n",
      "Epoch 18/30                                          \n",
      " - 5s - loss: 1.1909 - acc: 0.5685 - val_loss: 1.1901 - val_acc: 0.5700\n",
      "\n",
      "Epoch 19/30                                          \n",
      " - 5s - loss: 1.1896 - acc: 0.5690 - val_loss: 1.1888 - val_acc: 0.5705\n",
      "\n",
      "Epoch 20/30                                          \n",
      " - 5s - loss: 1.1882 - acc: 0.5710 - val_loss: 1.1872 - val_acc: 0.5729\n",
      "\n",
      "Epoch 21/30                                          \n",
      " - 5s - loss: 1.2134 - acc: 0.5756 - val_loss: 1.1808 - val_acc: 0.5949\n",
      "\n",
      "Epoch 22/30                                          \n",
      " - 6s - loss: 1.1797 - acc: 0.5949 - val_loss: 1.1778 - val_acc: 0.6017\n",
      "\n",
      "Epoch 23/30                                          \n",
      " - 5s - loss: 1.1764 - acc: 0.6039 - val_loss: 1.1733 - val_acc: 0.6109\n",
      "\n",
      "Epoch 24/30                                          \n",
      " - 5s - loss: 1.1701 - acc: 0.6185 - val_loss: 1.1595 - val_acc: 0.6452\n",
      "\n",
      "Epoch 25/30                                          \n",
      " - 5s - loss: 1.1531 - acc: 0.6686 - val_loss: 1.1478 - val_acc: 0.6857\n",
      "\n",
      "Epoch 26/30                                          \n",
      " - 5s - loss: 1.1484 - acc: 0.6818 - val_loss: 1.1438 - val_acc: 0.6959\n",
      "\n",
      "Epoch 27/30                                          \n",
      " - 5s - loss: 1.1457 - acc: 0.6886 - val_loss: 1.1432 - val_acc: 0.6831\n",
      "\n",
      "Epoch 28/30                                          \n",
      " - 5s - loss: 1.1385 - acc: 0.6965 - val_loss: 1.1338 - val_acc: 0.7143\n",
      "\n",
      "Epoch 29/30                                          \n",
      " - 5s - loss: 1.1342 - acc: 0.7091 - val_loss: 1.1306 - val_acc: 0.7125\n",
      "\n",
      "Epoch 30/30                                          \n",
      " - 5s - loss: 1.1348 - acc: 0.7061 - val_loss: 1.1228 - val_acc: 0.7346\n",
      "\n",
      "Best validation acc of epoch:                        \n",
      "0.7346416383066275                                   \n",
      "Train on 13672 samples, validate on 5860 samples                                  \n",
      "Epoch 1/30                                                                        \n",
      " - 6s - loss: 16.7034 - acc: 0.5620 - val_loss: 11.2769 - val_acc: 0.5635         \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30                                                                        \n",
      " - 5s - loss: 10.7081 - acc: 0.5628 - val_loss: 10.2921 - val_acc: 0.5635         \n",
      "\n",
      "Epoch 3/30                                                                        \n",
      " - 5s - loss: 10.0741 - acc: 0.5628 - val_loss: 9.8767 - val_acc: 0.5635          \n",
      "\n",
      "Epoch 4/30                                                                        \n",
      " - 6s - loss: 9.7580 - acc: 0.5628 - val_loss: 9.6350 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 5/30                                                                        \n",
      " - 6s - loss: 9.5601 - acc: 0.5628 - val_loss: 9.4726 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 6/30                                                                        \n",
      " - 6s - loss: 9.4213 - acc: 0.5628 - val_loss: 9.3540 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 7/30                                                                        \n",
      " - 6s - loss: 9.3172 - acc: 0.5628 - val_loss: 9.2626 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 8/30                                                                        \n",
      " - 6s - loss: 9.2353 - acc: 0.5628 - val_loss: 9.1893 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 9/30                                                                        \n",
      " - 7s - loss: 9.1688 - acc: 0.5628 - val_loss: 9.1289 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 10/30                                                                       \n",
      " - 8s - loss: 9.1134 - acc: 0.5628 - val_loss: 9.0781 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 11/30                                                                       \n",
      " - 6s - loss: 9.0663 - acc: 0.5628 - val_loss: 9.0345 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 12/30                                                                       \n",
      " - 7s - loss: 9.0256 - acc: 0.5628 - val_loss: 8.9966 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 13/30                                                                       \n",
      " - 6s - loss: 8.9900 - acc: 0.5628 - val_loss: 8.9632 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 14/30                                                                       \n",
      " - 6s - loss: 8.9586 - acc: 0.5628 - val_loss: 8.9336 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 15/30                                                                       \n",
      " - 8s - loss: 8.9305 - acc: 0.5628 - val_loss: 8.9070 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 16/30                                                                       \n",
      " - 7s - loss: 8.9053 - acc: 0.5628 - val_loss: 8.8830 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 17/30                                                                       \n",
      " - 8s - loss: 8.8824 - acc: 0.5628 - val_loss: 8.8612 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 18/30                                                                       \n",
      " - 7s - loss: 8.8615 - acc: 0.5628 - val_loss: 8.8412 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 19/30                                                                       \n",
      " - 6s - loss: 8.8424 - acc: 0.5628 - val_loss: 8.8229 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 20/30                                                                       \n",
      " - 6s - loss: 8.8248 - acc: 0.5628 - val_loss: 8.8060 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 21/30                                                                       \n",
      " - 6s - loss: 8.8085 - acc: 0.5628 - val_loss: 8.7904 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 22/30                                                                       \n",
      " - 6s - loss: 8.7934 - acc: 0.5628 - val_loss: 8.7758 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 23/30                                                                       \n",
      " - 9s - loss: 8.7794 - acc: 0.5628 - val_loss: 8.7622 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 24/30                                                                       \n",
      " - 7s - loss: 8.7662 - acc: 0.5628 - val_loss: 8.7495 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 25/30                                                                       \n",
      " - 8s - loss: 8.7539 - acc: 0.5628 - val_loss: 8.7376 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 26/30                                                                       \n",
      " - 9s - loss: 8.7423 - acc: 0.5628 - val_loss: 8.7263 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 27/30                                                                       \n",
      " - 8s - loss: 8.7314 - acc: 0.5628 - val_loss: 8.7157 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 28/30                                                                       \n",
      " - 7s - loss: 8.7211 - acc: 0.5628 - val_loss: 8.7057 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 29/30                                                                       \n",
      " - 8s - loss: 8.7114 - acc: 0.5628 - val_loss: 8.6962 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 30/30                                                                       \n",
      " - 7s - loss: 8.7021 - acc: 0.5628 - val_loss: 8.6872 - val_acc: 0.5635           \n",
      "\n",
      "Best validation acc of epoch:                                                     \n",
      "0.5634812286282562                                                                \n",
      "Train on 13672 samples, validate on 5860 samples                                  \n",
      "Epoch 1/30                                                                        \n",
      " - 7s - loss: 10.0245 - acc: 0.5622 - val_loss: 8.9351 - val_acc: 0.5635          \n",
      "\n",
      "Epoch 2/30                                                                        \n",
      " - 6s - loss: 8.7533 - acc: 0.5628 - val_loss: 8.6002 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 3/30                                                                        \n",
      " - 6s - loss: 8.5294 - acc: 0.5628 - val_loss: 8.4471 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 4/30                                                                        \n",
      " - 6s - loss: 8.4103 - acc: 0.5628 - val_loss: 8.3537 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 5/30                                                                        \n",
      " - 6s - loss: 8.3325 - acc: 0.5628 - val_loss: 8.2887 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 6/30                                                                        \n",
      " - 6s - loss: 8.2762 - acc: 0.5628 - val_loss: 8.2395 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 7/30                                                                        \n",
      " - 5s - loss: 8.2322 - acc: 0.5628 - val_loss: 8.1985 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 8/30                                                                        \n",
      " - 5s - loss: 8.1949 - acc: 0.5628 - val_loss: 8.1651 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 9/30                                                                        \n",
      " - 5s - loss: 8.1620 - acc: 0.5628 - val_loss: 8.1335 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 10/30                                                                       \n",
      " - 5s - loss: 8.1345 - acc: 0.5628 - val_loss: 8.1080 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 11/30                                                                       \n",
      " - 7s - loss: 8.1112 - acc: 0.5628 - val_loss: 8.0860 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 12/30                                                                       \n",
      " - 5s - loss: 8.0910 - acc: 0.5628 - val_loss: 8.0671 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 13/30                                                                       \n",
      " - 5s - loss: 8.0733 - acc: 0.5628 - val_loss: 8.0502 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 14/30                                                                       \n",
      " - 6s - loss: 8.0576 - acc: 0.5628 - val_loss: 8.0352 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 15/30                                                                       \n",
      " - 5s - loss: 8.0435 - acc: 0.5628 - val_loss: 8.0218 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 16/30                                                                       \n",
      " - 5s - loss: 8.0308 - acc: 0.5628 - val_loss: 8.0096 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 17/30                                                                       \n",
      " - 6s - loss: 8.0192 - acc: 0.5628 - val_loss: 7.9984 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 18/30                                                                       \n",
      " - 8s - loss: 8.0085 - acc: 0.5628 - val_loss: 7.9881 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 19/30                                                                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 6s - loss: 7.9988 - acc: 0.5628 - val_loss: 7.9787 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 20/30                                                                       \n",
      " - 6s - loss: 7.9898 - acc: 0.5628 - val_loss: 7.9699 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 21/30                                                                       \n",
      " - 5s - loss: 7.9814 - acc: 0.5628 - val_loss: 7.9618 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 22/30                                                                       \n",
      " - 6s - loss: 7.9736 - acc: 0.5628 - val_loss: 7.9542 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 23/30                                                                       \n",
      " - 6s - loss: 7.9663 - acc: 0.5628 - val_loss: 7.9471 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 24/30                                                                       \n",
      " - 5s - loss: 7.9595 - acc: 0.5628 - val_loss: 7.9405 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 25/30                                                                       \n",
      " - 6s - loss: 7.9530 - acc: 0.5628 - val_loss: 7.9342 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 26/30                                                                       \n",
      " - 5s - loss: 7.9470 - acc: 0.5628 - val_loss: 7.9283 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 27/30                                                                       \n",
      " - 5s - loss: 7.9413 - acc: 0.5628 - val_loss: 7.9227 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 28/30                                                                       \n",
      " - 5s - loss: 7.9358 - acc: 0.5628 - val_loss: 7.9174 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 29/30                                                                       \n",
      " - 5s - loss: 7.9307 - acc: 0.5628 - val_loss: 7.9123 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 30/30                                                                       \n",
      " - 8s - loss: 7.9258 - acc: 0.5628 - val_loss: 7.9076 - val_acc: 0.5635           \n",
      "\n",
      "Best validation acc of epoch:                                                     \n",
      "0.5634812286282562                                                                \n",
      "Train on 13672 samples, validate on 5860 samples                                  \n",
      "Epoch 1/30                                                                        \n",
      " - 6s - loss: 10.0485 - acc: 0.4685 - val_loss: 9.8248 - val_acc: 0.4365          \n",
      "\n",
      "Epoch 2/30                                                                        \n",
      " - 6s - loss: 9.5119 - acc: 0.4549 - val_loss: 9.7728 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 3/30                                                                        \n",
      " - 6s - loss: 9.6479 - acc: 0.4402 - val_loss: 9.6722 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 4/30                                                                        \n",
      " - 6s - loss: 9.6019 - acc: 0.4384 - val_loss: 9.6250 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 5/30                                                                        \n",
      " - 5s - loss: 9.5965 - acc: 0.4372 - val_loss: 9.5908 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 6/30                                                                        \n",
      " - 5s - loss: 9.5691 - acc: 0.4372 - val_loss: 9.5686 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 7/30                                                                        \n",
      " - 5s - loss: 9.5497 - acc: 0.4372 - val_loss: 9.5523 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 8/30                                                                        \n",
      " - 5s - loss: 9.5353 - acc: 0.4372 - val_loss: 9.5399 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 9/30                                                                        \n",
      " - 5s - loss: 9.5240 - acc: 0.4372 - val_loss: 9.5299 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 10/30                                                                       \n",
      " - 6s - loss: 9.5148 - acc: 0.4372 - val_loss: 9.5218 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 11/30                                                                       \n",
      " - 6s - loss: 9.5072 - acc: 0.4372 - val_loss: 9.5148 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 12/30                                                                       \n",
      " - 5s - loss: 9.5009 - acc: 0.4372 - val_loss: 9.5090 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 13/30                                                                       \n",
      " - 5s - loss: 9.4953 - acc: 0.4372 - val_loss: 9.5038 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 14/30                                                                       \n",
      " - 6s - loss: 9.4904 - acc: 0.4372 - val_loss: 9.4993 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 15/30                                                                       \n",
      " - 5s - loss: 9.4861 - acc: 0.4372 - val_loss: 9.4954 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 16/30                                                                       \n",
      " - 6s - loss: 9.4822 - acc: 0.4372 - val_loss: 9.4918 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 17/30                                                                       \n",
      " - 5s - loss: 9.4787 - acc: 0.4372 - val_loss: 9.4885 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 18/30                                                                       \n",
      " - 5s - loss: 9.4756 - acc: 0.4372 - val_loss: 9.4856 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 19/30                                                                       \n",
      " - 5s - loss: 9.4727 - acc: 0.4372 - val_loss: 9.4829 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 20/30                                                                       \n",
      " - 5s - loss: 9.4700 - acc: 0.4372 - val_loss: 9.4804 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 21/30                                                                       \n",
      " - 6s - loss: 9.4676 - acc: 0.4372 - val_loss: 9.4781 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 22/30                                                                       \n",
      " - 6s - loss: 9.4653 - acc: 0.4372 - val_loss: 9.4759 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 23/30                                                                       \n",
      " - 6s - loss: 9.4631 - acc: 0.4372 - val_loss: 9.4739 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 24/30                                                                       \n",
      " - 5s - loss: 9.4611 - acc: 0.4372 - val_loss: 9.4721 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 25/30                                                                       \n",
      " - 6s - loss: 9.4592 - acc: 0.4372 - val_loss: 9.4703 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 26/30                                                                       \n",
      " - 5s - loss: 9.4574 - acc: 0.4372 - val_loss: 9.4686 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 27/30                                                                       \n",
      " - 5s - loss: 9.4557 - acc: 0.4372 - val_loss: 9.4671 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 28/30                                                                       \n",
      " - 5s - loss: 9.4541 - acc: 0.4372 - val_loss: 9.4656 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 29/30                                                                       \n",
      " - 5s - loss: 9.4526 - acc: 0.4372 - val_loss: 9.4642 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 30/30                                                                       \n",
      " - 5s - loss: 9.4511 - acc: 0.4372 - val_loss: 9.4629 - val_acc: 0.4365           \n",
      "\n",
      "Best validation acc of epoch:                                                     \n",
      "0.4365187713717438                                                                \n",
      "Train on 13672 samples, validate on 5860 samples                                  \n",
      "Epoch 1/30                                                                        \n",
      " - 6s - loss: 14.4691 - acc: 0.5626 - val_loss: 10.1192 - val_acc: 0.5635         \n",
      "\n",
      "Epoch 2/30                                                                        \n",
      " - 5s - loss: 9.8392 - acc: 0.5628 - val_loss: 9.6278 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 3/30                                                                        \n",
      " - 5s - loss: 9.5265 - acc: 0.5628 - val_loss: 9.4250 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 4/30                                                                        \n",
      " - 5s - loss: 9.3729 - acc: 0.5628 - val_loss: 9.3081 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 5/30                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 5s - loss: 9.2773 - acc: 0.5628 - val_loss: 9.2298 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 6/30                                                                        \n",
      " - 5s - loss: 9.2106 - acc: 0.5628 - val_loss: 9.1728 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 7/30                                                                        \n",
      " - 5s - loss: 9.1606 - acc: 0.5628 - val_loss: 9.1290 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 8/30                                                                        \n",
      " - 5s - loss: 9.1213 - acc: 0.5628 - val_loss: 9.0939 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 9/30                                                                        \n",
      " - 5s - loss: 9.0895 - acc: 0.5628 - val_loss: 9.0650 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 10/30                                                                       \n",
      " - 5s - loss: 9.0630 - acc: 0.5628 - val_loss: 9.0407 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 11/30                                                                       \n",
      " - 5s - loss: 9.0405 - acc: 0.5628 - val_loss: 9.0199 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 12/30                                                                       \n",
      " - 5s - loss: 9.0211 - acc: 0.5628 - val_loss: 9.0017 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 13/30                                                                       \n",
      " - 5s - loss: 9.0041 - acc: 0.5628 - val_loss: 8.9858 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 14/30                                                                       \n",
      " - 5s - loss: 8.9891 - acc: 0.5628 - val_loss: 8.9717 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 15/30                                                                       \n",
      " - 5s - loss: 8.9756 - acc: 0.5628 - val_loss: 8.9590 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 16/30                                                                       \n",
      " - 5s - loss: 8.9636 - acc: 0.5628 - val_loss: 8.9475 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 17/30                                                                       \n",
      " - 5s - loss: 8.9527 - acc: 0.5628 - val_loss: 8.9371 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 18/30                                                                       \n",
      " - 5s - loss: 8.9427 - acc: 0.5628 - val_loss: 8.9276 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 19/30                                                                       \n",
      " - 5s - loss: 8.9336 - acc: 0.5628 - val_loss: 8.9189 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 20/30                                                                       \n",
      " - 5s - loss: 8.9252 - acc: 0.5628 - val_loss: 8.9108 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 21/30                                                                       \n",
      " - 5s - loss: 8.9174 - acc: 0.5628 - val_loss: 8.9033 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 22/30                                                                       \n",
      " - 6s - loss: 8.9102 - acc: 0.5628 - val_loss: 8.8964 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 23/30                                                                       \n",
      " - 5s - loss: 8.9035 - acc: 0.5628 - val_loss: 8.8899 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 24/30                                                                       \n",
      " - 6s - loss: 8.8973 - acc: 0.5628 - val_loss: 8.8838 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 25/30                                                                       \n",
      " - 6s - loss: 8.8914 - acc: 0.5628 - val_loss: 8.8781 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 26/30                                                                       \n",
      " - 6s - loss: 8.8859 - acc: 0.5628 - val_loss: 8.8728 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 27/30                                                                       \n",
      " - 6s - loss: 8.8806 - acc: 0.5628 - val_loss: 8.8677 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 28/30                                                                       \n",
      " - 5s - loss: 8.8757 - acc: 0.5628 - val_loss: 8.8630 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 29/30                                                                       \n",
      " - 5s - loss: 8.8711 - acc: 0.5628 - val_loss: 8.8584 - val_acc: 0.5635           \n",
      "\n",
      "Epoch 30/30                                                                       \n",
      " - 6s - loss: 8.8667 - acc: 0.5628 - val_loss: 8.8541 - val_acc: 0.5635           \n",
      "\n",
      "Best validation acc of epoch:                                                     \n",
      "0.5634812286282562                                                                \n",
      "Train on 13672 samples, validate on 5860 samples                                  \n",
      "Epoch 1/30                                                                        \n",
      " - 6s - loss: 11.9216 - acc: 0.4386 - val_loss: 9.9428 - val_acc: 0.4365          \n",
      "\n",
      "Epoch 2/30                                                                        \n",
      " - 6s - loss: 9.8787 - acc: 0.4372 - val_loss: 9.8525 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 3/30                                                                        \n",
      " - 6s - loss: 9.8236 - acc: 0.4372 - val_loss: 9.8184 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 4/30                                                                        \n",
      " - 5s - loss: 9.7980 - acc: 0.4372 - val_loss: 9.7995 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 5/30                                                                        \n",
      " - 6s - loss: 8.0559 - acc: 0.5066 - val_loss: 6.7950 - val_acc: 0.5213           \n",
      "\n",
      "Epoch 6/30                                                                        \n",
      " - 6s - loss: 3.4606 - acc: 0.7104 - val_loss: 2.9502 - val_acc: 0.7288           \n",
      "\n",
      "Epoch 7/30                                                                        \n",
      " - 6s - loss: 2.8529 - acc: 0.7446 - val_loss: 2.9923 - val_acc: 0.7457           \n",
      "\n",
      "Epoch 8/30                                                                        \n",
      " - 6s - loss: 2.6016 - acc: 0.7561 - val_loss: 2.4517 - val_acc: 0.7647           \n",
      "\n",
      "Epoch 9/30                                                                        \n",
      " - 6s - loss: 2.4507 - acc: 0.7649 - val_loss: 2.3686 - val_acc: 0.7698           \n",
      "\n",
      "Epoch 10/30                                                                       \n",
      " - 6s - loss: 2.3085 - acc: 0.7727 - val_loss: 2.2550 - val_acc: 0.7766           \n",
      "\n",
      "Epoch 11/30                                                                       \n",
      " - 6s - loss: 2.2124 - acc: 0.7757 - val_loss: 2.1412 - val_acc: 0.7780           \n",
      "\n",
      "Epoch 12/30                                                                       \n",
      " - 7s - loss: 2.1147 - acc: 0.7790 - val_loss: 2.2169 - val_acc: 0.7597           \n",
      "\n",
      "Epoch 13/30                                                                       \n",
      " - 6s - loss: 2.0503 - acc: 0.7820 - val_loss: 2.0782 - val_acc: 0.7828           \n",
      "\n",
      "Epoch 14/30                                                                       \n",
      " - 6s - loss: 1.9793 - acc: 0.7840 - val_loss: 1.9540 - val_acc: 0.7852           \n",
      "\n",
      "Epoch 15/30                                                                       \n",
      " - 6s - loss: 1.9251 - acc: 0.7874 - val_loss: 1.9308 - val_acc: 0.7903           \n",
      "\n",
      "Epoch 16/30                                                                       \n",
      " - 6s - loss: 1.8860 - acc: 0.7913 - val_loss: 1.8682 - val_acc: 0.7899           \n",
      "\n",
      "Epoch 17/30                                                                       \n",
      " - 6s - loss: 1.8484 - acc: 0.7911 - val_loss: 1.8356 - val_acc: 0.7916           \n",
      "\n",
      "Epoch 18/30                                                                       \n",
      " - 6s - loss: 1.8177 - acc: 0.7932 - val_loss: 1.8091 - val_acc: 0.7954           \n",
      "\n",
      "Epoch 19/30                                                                       \n",
      " - 6s - loss: 1.7814 - acc: 0.7937 - val_loss: 1.7938 - val_acc: 0.7973           \n",
      "\n",
      "Epoch 20/30                                                                       \n",
      " - 6s - loss: 1.7560 - acc: 0.7953 - val_loss: 1.7656 - val_acc: 0.7935           \n",
      "\n",
      "Epoch 21/30                                                                       \n",
      " - 6s - loss: 1.7358 - acc: 0.7970 - val_loss: 1.7636 - val_acc: 0.7908           \n",
      "\n",
      "Epoch 22/30                                                                       \n",
      " - 6s - loss: 1.7108 - acc: 0.7964 - val_loss: 1.7456 - val_acc: 0.7920           \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30                                                                       \n",
      " - 6s - loss: 1.6921 - acc: 0.7974 - val_loss: 1.7117 - val_acc: 0.7990           \n",
      "\n",
      "Epoch 24/30                                                                       \n",
      " - 6s - loss: 1.6734 - acc: 0.7990 - val_loss: 1.6775 - val_acc: 0.8015           \n",
      "\n",
      "Epoch 25/30                                                                       \n",
      " - 6s - loss: 1.6520 - acc: 0.7979 - val_loss: 1.6715 - val_acc: 0.7995           \n",
      "\n",
      "Epoch 26/30                                                                       \n",
      " - 6s - loss: 1.6427 - acc: 0.8002 - val_loss: 1.6556 - val_acc: 0.8000           \n",
      "\n",
      "Epoch 27/30                                                                       \n",
      " - 6s - loss: 1.6266 - acc: 0.8020 - val_loss: 1.6581 - val_acc: 0.8007           \n",
      "\n",
      "Epoch 28/30                                                                       \n",
      " - 6s - loss: 1.6154 - acc: 0.8005 - val_loss: 1.6297 - val_acc: 0.8034           \n",
      "\n",
      "Epoch 29/30                                                                       \n",
      " - 6s - loss: 1.6012 - acc: 0.8023 - val_loss: 1.6148 - val_acc: 0.8039           \n",
      "\n",
      "Epoch 30/30                                                                       \n",
      " - 6s - loss: 1.5933 - acc: 0.8038 - val_loss: 1.6071 - val_acc: 0.8043           \n",
      "\n",
      "Best validation acc of epoch:                                                     \n",
      "0.8042662116854671                                                                \n",
      "Train on 13672 samples, validate on 5860 samples                                  \n",
      "Epoch 1/30                                                                        \n",
      " - 6s - loss: 9.6002 - acc: 0.4389 - val_loss: 9.4954 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 2/30                                                                        \n",
      " - 6s - loss: 9.4581 - acc: 0.4372 - val_loss: 9.4510 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 3/30                                                                        \n",
      " - 6s - loss: 9.4278 - acc: 0.4372 - val_loss: 9.4303 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 4/30                                                                        \n",
      " - 6s - loss: 9.4114 - acc: 0.4372 - val_loss: 9.4176 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 5/30                                                                        \n",
      " - 8s - loss: 9.4006 - acc: 0.4372 - val_loss: 9.4086 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 6/30                                                                        \n",
      " - 11s - loss: 9.3928 - acc: 0.4372 - val_loss: 9.4019 - val_acc: 0.4365          \n",
      "\n",
      "Epoch 7/30                                                                        \n",
      " - 7s - loss: 9.3868 - acc: 0.4372 - val_loss: 9.3966 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 8/30                                                                        \n",
      " - 7s - loss: 9.3819 - acc: 0.4372 - val_loss: 9.3922 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 9/30                                                                        \n",
      " - 6s - loss: 9.3779 - acc: 0.4372 - val_loss: 9.3886 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 10/30                                                                       \n",
      " - 6s - loss: 9.3744 - acc: 0.4372 - val_loss: 9.3855 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 11/30                                                                       \n",
      " - 7s - loss: 9.3715 - acc: 0.4372 - val_loss: 9.3828 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 12/30                                                                       \n",
      " - 6s - loss: 9.3689 - acc: 0.4372 - val_loss: 9.3803 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 13/30                                                                       \n",
      " - 6s - loss: 9.3666 - acc: 0.4372 - val_loss: 9.3782 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 14/30                                                                       \n",
      " - 6s - loss: 9.3646 - acc: 0.4372 - val_loss: 9.3763 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 15/30                                                                       \n",
      " - 7s - loss: 9.3628 - acc: 0.4372 - val_loss: 9.3747 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 16/30                                                                       \n",
      " - 7s - loss: 9.3610 - acc: 0.4372 - val_loss: 9.3732 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 17/30                                                                       \n",
      " - 7s - loss: 9.3596 - acc: 0.4372 - val_loss: 9.3718 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 18/30                                                                       \n",
      " - 7s - loss: 9.3582 - acc: 0.4372 - val_loss: 9.3704 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 19/30                                                                       \n",
      " - 5s - loss: 9.3568 - acc: 0.4372 - val_loss: 9.3692 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 20/30                                                                       \n",
      " - 6s - loss: 9.3557 - acc: 0.4372 - val_loss: 9.3681 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 21/30                                                                       \n",
      " - 6s - loss: 9.3546 - acc: 0.4372 - val_loss: 9.3671 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 22/30                                                                       \n",
      " - 6s - loss: 9.3535 - acc: 0.4372 - val_loss: 9.3660 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 23/30                                                                       \n",
      " - 6s - loss: 9.3526 - acc: 0.4372 - val_loss: 9.3651 - val_acc: 0.4365           \n",
      "\n",
      "Epoch 24/30                                                                       \n",
      "  6%|▌         | 6/100 [19:46<4:25:53, 169.72s/it, best loss: -0.8042662116854671]"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best_run, best_model = optim.minimize(model=model_optimizer,\n",
    "                                      data=data_bow,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=100,\n",
    "                                      trials=trials,\n",
    "                                     notebook_name='Sequential_bow')\n",
    "print(\"Best performing model chosen hyper-parameters:\")\n",
    "print(best_run)\n",
    "best_model.save('../model/best_Hyperopt_NN_bow_optimizer_500.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beste Regularization: \n",
    "\n",
    "L1 in der ersten Layer = 2.0036577552673407e-06\n",
    "\n",
    "L2 in der zweiten Layer = 0.05407632514834404"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train best model\n",
    "Neues Training des besten Modells, welches Optimiert bezüglich der Hyperparameter ist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(network_history):\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot(network_history.history['loss'])\n",
    "    plt.plot(network_history.history['val_loss'])\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    #plt.show()\n",
    "    plt.savefig(\"../build/plots/bow/500/history_bow_best.pdf\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = data_bow()\n",
    "best_model = load_model('../model/best_Hyperopt_NN_bow_regularization_500.hdf5')\n",
    "model = Sequential.from_config(best_model.get_config())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '../model/best_Hyperopt_NN_bow_trained_500.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='Adagrad',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train.values, Y_train.values, validation_split=0.3,\n",
    "                    epochs=100,batch_size=64, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of best model\n",
    "Betrachten des trainierten Modells. Darstellung der Confusion Matrix, Overtraining Plot und ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = load_model('../model/best_Hyperopt_NN_bow_trained_500.hdf5')\n",
    "y_pred = best_model.predict(X_test.values, batch_size=64, verbose=1)\n",
    "y_pred_train = best_model.predict(X_train.values, batch_size=64, verbose=1)\n",
    "y_pred_bool = np.round(y_pred[:,0])\n",
    "Y_test = pd.DataFrame({\"label\":Y_test,\"prediction\":y_pred[:,0],\"prediction_bool\":y_pred_bool})\n",
    "Y_train = pd.DataFrame({\"label\":Y_train,\"prediction\":y_pred_train[:,0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(Y_test['label'], Y_test['prediction_bool']))\n",
    "\n",
    "#Confusion Matrix\n",
    "cnfn_matrix = pd.crosstab(Y_test['label'], Y_test['prediction_bool'], rownames=['Actual'], colnames=['Predicted'])\n",
    "print(cnfn_matrix)\n",
    "cnfn_matrix.columns = ['fake','real']\n",
    "cnfn_matrix = cnfn_matrix.rename_axis(\"Predicted\", axis=\"columns\")\n",
    "cnfn_matrix.rename(index = {0.0: \"fake\", 1.0:'real'}, inplace = True) \n",
    "cnfn_matrix = cnfn_matrix/Y_test.shape[0]\n",
    "sn.heatmap(cnfn_matrix, annot=True , cmap='viridis')\n",
    "#plt.show()\n",
    "plt.savefig(\"../build/plots/bow/500/cnfsn_mtx_bow_best_nn.pdf\")\n",
    "plt.close()\n",
    "\n",
    "#Overtraining test\n",
    "plt.hist(Y_test.prediction[Y_test.label == 0],label=\"fake test\", alpha = 0.4, color = \"r\",density=True)\n",
    "plt.hist(Y_train.prediction[Y_train.label == 0],label='fake train', alpha = 0.4, color = 'r', histtype='step',density=True)\n",
    "plt.hist(Y_test.prediction[Y_test.label == 1],label = \"real test\",alpha = 0.4, color = \"b\",density=True)\n",
    "plt.hist(Y_train.prediction[Y_train.label == 1],label='real train', alpha = 0.4, color = 'b', histtype='step',density=True)\n",
    "\n",
    "plt.xlabel(\"Prediction Probability\")\n",
    "plt.ylabel(\"density\")\n",
    "plt.legend(loc='upper center')\n",
    "#plt.show()\n",
    "plt.savefig(\"../build/plots/bow/500/prob_bow_best_nn.pdf\")\n",
    "plt.close()\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "fpr, tpr, _ = roc_curve(Y_test.label, Y_test.prediction)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.show()\n",
    "plt.savefig(\"../build/plots/bow/500/roc_Hyperopt_bow_best_nn.pdf\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation\n",
    "\n",
    "### Wordcloud confusion matrix\n",
    "\n",
    "Darstellung der Wordhäufigkeiten in WordClouds für FP,FN,TP,TN getrennt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FP = Y_test[(Y_test.prediction_bool== 1) & (Y_test.label == 0)]\n",
    "FN = Y_test[(Y_test.prediction_bool== 0) & (Y_test.label == 1)]\n",
    "TP = Y_test[(Y_test.prediction_bool== 1) & (Y_test.label == 1)]\n",
    "TN = Y_test[(Y_test.prediction_bool== 0) & (Y_test.label == 0)]\n",
    "X_FP = X_test.loc[FP.index]\n",
    "X_FN = X_test.loc[FN.index]\n",
    "X_TP = X_test.loc[TP.index]\n",
    "X_TN = X_test.loc[TN.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotWordcloud_cnfn(TN,FN,FP,TP):    \n",
    "    TN = TN.sum().to_dict()\n",
    "    FN = FN.sum().to_dict()\n",
    "    FP = FP.sum().to_dict()\n",
    "    TP = TP.sum().to_dict()\n",
    "    \n",
    "    pad = 5\n",
    "    \n",
    "    fig = plt.figure(figsize=(15,10),dpi=100)\n",
    "\n",
    "    ax = plt.subplot(2, 2, 1)\n",
    "    wordcloud = WordCloud(background_color='black',\n",
    "                          width=1920,\n",
    "                          height=1080,\n",
    "                          mask=np.array(Image.open('../data/pictures/trump_silhouette.png'))\n",
    "                          ).generate_from_frequencies(TN)\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.margins(x=0, y=0)\n",
    "\n",
    "    ax = plt.subplot(2, 2, 2)\n",
    "    wordcloud = WordCloud(background_color='black',\n",
    "                          width=1920,\n",
    "                          height=1080,\n",
    "                          mask= np.array(Image.open('../data/pictures/trump_silhouette.png'))\n",
    "                          ).generate_from_frequencies(FP)\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.margins(x=0, y=0)\n",
    "\n",
    "    ax = plt.subplot(2, 2, 3)\n",
    "    wordcloud = WordCloud(background_color='black',\n",
    "                          width=1920,\n",
    "                          height=1080,\n",
    "                          mask=np.array(Image.open('../data/pictures/USA.jpg'))\n",
    "                          ).generate_from_frequencies(FN)\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.margins(x=0, y=0)\n",
    "\n",
    "    plt.subplot(2, 2, 4)\n",
    "    wordcloud = WordCloud(background_color='black',\n",
    "                          width=1920,\n",
    "                          height=1080,\n",
    "                          mask=np.array(Image.open('../data/pictures/USA.jpg'))\n",
    "                          ).generate_from_frequencies(TP)\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.figtext(0.5, 1.09, r\"Prediction\", {'fontsize': 30},\n",
    "         horizontalalignment='center',\n",
    "         verticalalignment='top')\n",
    "    plt.figtext(0.25, 1.02, r\"fake\", {'fontsize': 20},\n",
    "         horizontalalignment='center',\n",
    "         verticalalignment='bottom',)\n",
    "    plt.figtext(0.75, 1.02, r\"real\", {'fontsize': 20},\n",
    "         horizontalalignment='center',\n",
    "         verticalalignment='bottom',)\n",
    "    \n",
    "    plt.figtext(-0.07, 0.5, r\"Actual\", {'fontsize': 30},\n",
    "         horizontalalignment='left',\n",
    "         verticalalignment='center',\n",
    "         rotation=90)\n",
    "    plt.figtext(0.00, 0.75, r\"fake\", {'fontsize': 20},\n",
    "         horizontalalignment='right',\n",
    "         verticalalignment='center',)\n",
    "    plt.figtext(0.00, 0.25, r\"real\", {'fontsize': 20},\n",
    "         horizontalalignment='right',\n",
    "         verticalalignment='center',)\n",
    "    \n",
    "    plt.margins(x=0, y=0)\n",
    "    plt.tight_layout()\n",
    "    #plt.show()\n",
    "    plt.savefig(\"../build/plots/bow/500/cnfn_wordcloud.pdf\", bbox_inches = 'tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotWordcloud_cnfn(X_TN,X_FN,X_FP,X_TP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordcloud fake real news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotWordcloud(content,t):\n",
    "    if(t!=\"\"):\n",
    "       mask = np.array(Image.open('../data/pictures/'+t))\n",
    "    else:\n",
    "        mask=None\n",
    "        \n",
    "\n",
    "    content = content.sum().to_dict()\n",
    "    wordcloud = WordCloud(background_color='black',\n",
    "                      width=1920,\n",
    "                      height=1080,\n",
    "                      mask=mask\n",
    "                      ).generate_from_frequencies(content)\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.margins(x=0, y=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_test.append(X_train)\n",
    "y = Y_test.append(Y_train)\n",
    "plt.figure(dpi=200)\n",
    "plotWordcloud(X[y.label==0],\"trump_silhouette.png\")\n",
    "#plt.show()\n",
    "plt.savefig(\"../build/plots/fake_wordcloud.pdf\",bbox_inches='tight',pad_inches = 0)\n",
    "plt.close()\n",
    "plt.figure(dpi=200)\n",
    "plotWordcloud(X[y.label==1],\"USA.jpg\")\n",
    "#plt.show()\n",
    "plt.savefig(\"../build/plots/real_wordcloud.pdf\",bbox_inches='tight',pad_inches = 0)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Untersuchung der first layer\n",
    "\n",
    "Summieren der Beträge aller Gewichte eines Neurons ohne Offset und anschließende Darstellung in WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = X_test.columns\n",
    "first_weights = best_model.layers[0].get_weights()[0]\n",
    "first_weights = pd.DataFrame(first_weights.transpose())\n",
    "first_weights.columns = words\n",
    "first_weightabs = np.abs(first_weights)\n",
    "first_weightsum = first_weightabs.sum(axis=0)\n",
    "content = np.abs(first_weightsum).to_dict()\n",
    "wordcloud = WordCloud(background_color='black',\n",
    "                      width=1920,\n",
    "                      height=1080\n",
    "                      ).generate_from_frequencies(content)\n",
    "plt.figure(dpi=100)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.margins(x=0, y=0)\n",
    "#plt.show()\n",
    "plt.savefig(\"../build/plots/bow/500/weights_wordcloud.pdf\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untersuchung der Confusion Matrix mithilfe der wichtigsten 10 Wörter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_weights = first_weightsum.sort_values(ascending=False)\n",
    "best_words = sorted_weights[:10].index\n",
    "\n",
    "fig = plt.figure(figsize=(15,10),dpi=100)\n",
    "\n",
    "ax = plt.subplot(2, 2, 1)\n",
    "(X_TN[best_words].sum()/X_TN.shape[0]).plot(kind='bar',label=\"TN\",color='r')\n",
    "plt.margins(x=0, y=0)\n",
    "plt.ylabel(\"mittlere Worthäufigkeit\")\n",
    "plt.ylim(0,1)\n",
    "\n",
    "ax = plt.subplot(2, 2, 2)\n",
    "(X_FP[best_words].sum()/X_FP.shape[0]).plot(kind='bar',label=\"FP\",color='g')\n",
    "plt.margins(x=0, y=0)\n",
    "plt.ylabel(\"mittlere Worthäufigkeit\")\n",
    "plt.ylim(0,1)\n",
    "\n",
    "ax = plt.subplot(2, 2, 3)\n",
    "(X_FN[best_words].sum()/X_FN.shape[0]).plot(kind='bar',label=\"FN\",color='k')\n",
    "plt.margins(x=0, y=0)\n",
    "plt.ylabel(\"mittlere Worthäufigkeit\")\n",
    "plt.ylim(0,1)\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "(X_TP[best_words].sum()/X_TP.shape[0]).plot(kind='bar',label=\"TP\",color='b')\n",
    "plt.margins(x=0, y=0)\n",
    "plt.ylabel(\"mittlere Worthäufigkeit\")\n",
    "plt.ylim(0,1)\n",
    "    \n",
    "plt.figtext(0.5, 1.09, r\"Prediction\", {'fontsize': 30},\n",
    "     horizontalalignment='center',\n",
    "     verticalalignment='top')\n",
    "plt.figtext(0.25, 1.02, r\"fake\", {'fontsize': 20},\n",
    "     horizontalalignment='center',\n",
    "     verticalalignment='bottom',)\n",
    "plt.figtext(0.75, 1.02, r\"real\", {'fontsize': 20},\n",
    "     horizontalalignment='center',\n",
    "     verticalalignment='bottom',)\n",
    "    \n",
    "plt.figtext(-0.07, 0.5, r\"Actual\", {'fontsize': 30},\n",
    "     horizontalalignment='left',\n",
    "     verticalalignment='center',\n",
    "     rotation=90)\n",
    "plt.figtext(0.00, 0.75, r\"fake\", {'fontsize': 20},\n",
    "     horizontalalignment='right',\n",
    "     verticalalignment='center',)\n",
    "plt.figtext(0.00, 0.25, r\"real\", {'fontsize': 20},\n",
    "     horizontalalignment='right',\n",
    "     verticalalignment='center',)\n",
    "    \n",
    "plt.margins(x=0, y=0)\n",
    "plt.tight_layout()\n",
    "#plt.show()\n",
    "plt.savefig(\"../build/plots/bow/500/cnfn_hist.pdf\", bbox_inches = 'tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF Vergleichsmodell\n",
    "Training einer RF auf dem bow Input und Evaluierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier(n_estimators=100, max_depth=10,random_state=0,criterion='entropy')\n",
    "RF.fit(X_train.values,Y_train.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_bool_RF = RF.predict(X_test.values)\n",
    "y_pred_RF = RF.predict_proba(X_test.values)\n",
    "y_pred_RF = y_pred_RF[:,1]\n",
    "y_pred_train_RF = RF.predict_proba(X_train.values)\n",
    "y_pred_train_RF = y_pred_train_RF[:,1]\n",
    "Y_test['prediction_RF'] = y_pred_RF\n",
    "Y_test['prediction_bool_RF'] = y_pred_bool_RF\n",
    "Y_train['prediction_RF'] = y_pred_train_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test.label, Y_test.prediction_bool_RF))\n",
    "\n",
    "#Confusion Matrix\n",
    "cnfn_matrix = pd.crosstab(Y_test.label, Y_test.prediction_bool_RF, rownames=['Actual'], colnames=['Predicted'])\n",
    "print(cnfn_matrix)\n",
    "cnfn_matrix.columns = ['fake','real']\n",
    "cnfn_matrix = cnfn_matrix.rename_axis(\"Predicted\", axis=\"columns\")\n",
    "cnfn_matrix.rename(index = {0.0: \"fake\", 1.0:'real'}, inplace = True) \n",
    "cnfn_matrix = cnfn_matrix/Y_test.shape[0]\n",
    "sn.heatmap(cnfn_matrix, annot=True , cmap='viridis')\n",
    "#plt.show()\n",
    "plt.savefig(\"../build/plots/bow/500/RF/cnfsn_mtx_bow_best_nn.pdf\")\n",
    "plt.close()\n",
    "\n",
    "#Overtraining test\n",
    "bin_edges = np.linspace(0,1,11)\n",
    "plt.hist(Y_test.prediction_RF[Y_test.label == 0],label=\"fake test\", alpha = 0.4, color = \"r\",density=True,bins=bin_edges)\n",
    "plt.hist(Y_train.prediction_RF[Y_train.label == 0],label='fake train', alpha = 0.4, color = 'r', histtype='step',density=True,bins=bin_edges)\n",
    "plt.hist(Y_test.prediction_RF[Y_test.label == 1],label = \"real test\",alpha = 0.4, color = \"b\",density=True,bins=bin_edges)\n",
    "plt.hist(Y_train.prediction_RF[Y_train.label == 1],label='real train', alpha = 0.4, color = 'b', histtype='step',density=True,bins=bin_edges)\n",
    "\n",
    "plt.xlabel(\"Prediction Probability\")\n",
    "plt.ylabel(\"density\")\n",
    "plt.legend(loc='upper center')\n",
    "#plt.show()\n",
    "plt.savefig(\"../build/plots/bow/500/RF/prob_bow_best_nn.pdf\")\n",
    "plt.close()\n",
    "\n",
    "fpr_RF = dict()\n",
    "tpr_RF = dict()\n",
    "roc_auc_RF = dict()\n",
    "fpr_RF, tpr_RF, _ = roc_curve(Y_test.label, Y_test.prediction_RF)\n",
    "roc_auc_RF = auc(fpr_RF, tpr_RF)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr_RF, tpr_RF, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc_RF)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.show()\n",
    "plt.savefig(\"../build/plots/bow/500/RF/roc_Hyperopt_bow_best_nn.pdf\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison\n",
    "Vergleich des Sequential mit dem RF in der ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='Sequential (area = %0.2f)' % roc_auc)\n",
    "plt.plot(fpr_RF, tpr_RF, color='darkred',\n",
    "         lw=lw, label='RandomForest (area = %0.2f)' % roc_auc_RF)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.show()\n",
    "plt.savefig(\"../build/plots/bow/500/roc_comparison.pdf\")\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
